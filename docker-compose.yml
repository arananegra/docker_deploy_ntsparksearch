version: '2'
# docker-compose build --no-cache ntsparksearch
# docker-compose build ntsparksearch
# docker-compose up ntsparksearch
# docker-compose down ntsparksearch

services:
  ntsparksearch:
    build:
      context: ./NtSparkSearch
    image: nt_spark_search_image
    extra_hosts:
      - "database:172.16.239.11"
      #- "redis:172.16.239.12"
    networks:
      ci_co_net:
        ipv4_address: 172.16.239.10
    container_name: ntsparksearch_docker
    ports:
      - 5000:5000
    #link a otro contenedor llamado mongodb_ntsparksearch --> cuando este
    # se levanta, se levanta el del mongo
    links:
      - mongodb_ntsparksearch:ntsparksearch_docker
      #- redis_ntsparksearch:ntsparksearch_docker
    # volumen donde a√±adir ficheros a usar por programa: excel etc.
    volumes:
      - ./volumes/input_files:/usr/spark-2.1.0/input
      - ./volumes/output_files:/usr/spark-2.1.0/output
  
  mongodb_ntsparksearch:
    image: mongo
    container_name: mongodb_ntsparksearch
    networks:
      ci_co_net:
        ipv4_address: 172.16.239.11
    mem_limit: 256m
    ports:
      - 8082:27017
    volumes:
      - ./volumes/mongodb_recovery:/data/db
    restart: always

#  redis_ntsparksearch:
#    build:
#      context: ./redis_custom_image
#    image: redis_custom_image
#    container_name: redis_ntsparksearch
#    networks:
#      ci_co_net:
#        ipv4_address: 172.16.239.12
#    ports:
#      - 6379:6379
#    restart: always

# red interna de los contenedores
# docker
networks:
  ci_co_net:
    driver: bridge
    ipam:
      driver: default
      config:
      - subnet: 172.16.239.0/24
        gateway: 172.16.239.2

    
